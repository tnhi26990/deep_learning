{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4dd561f-db01-42fe-99c5-672df0b0dc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 17:51:07.652056: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/trannhi/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import sklearn.model_selection\n",
    "import sklearn.preprocessing\n",
    "import string\n",
    "from keras.layers import TextVectorization\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from joblib import Parallel,delayed\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec61209c-4fa3-4a9d-9dc3-2ac513bb0a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "website_categories = pd.read_csv('website_categories.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "409f2fe6-70ed-4d90-9369-aca4fcdb1469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>touristscavengerhunt.com</td>\n",
       "      <td>/Travel</td>\n",
       "      <td>explore the city with our 2-3 hour tourist sca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>plannedspontaneityhiking.com</td>\n",
       "      <td>/Hobbies &amp; Leisure/Outdoors/Hiking &amp; Camping</td>\n",
       "      <td>a blog about hiking around the midwest and beyond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>www.utvdirect.com</td>\n",
       "      <td>/Autos &amp; Vehicles/Motor Vehicles (By Type)/Off...</td>\n",
       "      <td>find the right side by side accessories for yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>www.debrovys.com</td>\n",
       "      <td>/Business &amp; Industrial/Construction &amp; Maintena...</td>\n",
       "      <td>debrovy's is the ideal tarp manufacturer in th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>www.urbanbarn.com</td>\n",
       "      <td>/Home &amp; Garden/Home Furnishings</td>\n",
       "      <td>furniture and accessories for your home and of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27059</th>\n",
       "      <td>98999</td>\n",
       "      <td>historyfiles.co.uk</td>\n",
       "      <td>/Reference/Geographic Reference</td>\n",
       "      <td>an extensive collection of information coverin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27060</th>\n",
       "      <td>99000</td>\n",
       "      <td>therugbynetwork.com</td>\n",
       "      <td>/Sports/Team Sports/Rugby</td>\n",
       "      <td>watch every game of major league rugby live an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27061</th>\n",
       "      <td>99001</td>\n",
       "      <td>theseniorlist.com</td>\n",
       "      <td>/People &amp; Society/Seniors &amp; Retirement</td>\n",
       "      <td>the senior list offers the best advice for sen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27062</th>\n",
       "      <td>99003</td>\n",
       "      <td>mypetchicken.com</td>\n",
       "      <td>/Business &amp; Industrial/Agriculture &amp; Forestry/...</td>\n",
       "      <td>backyard chickens from my pet chicken: offerin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27063</th>\n",
       "      <td>99010</td>\n",
       "      <td>lexico.com</td>\n",
       "      <td>/Reference/General Reference/Dictionaries &amp; En...</td>\n",
       "      <td>find definitions, language articles, and help ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27064 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                           url  \\\n",
       "0              7      touristscavengerhunt.com   \n",
       "1             11  plannedspontaneityhiking.com   \n",
       "2             19             www.utvdirect.com   \n",
       "3             20              www.debrovys.com   \n",
       "4             23             www.urbanbarn.com   \n",
       "...          ...                           ...   \n",
       "27059      98999            historyfiles.co.uk   \n",
       "27060      99000           therugbynetwork.com   \n",
       "27061      99001             theseniorlist.com   \n",
       "27062      99003              mypetchicken.com   \n",
       "27063      99010                    lexico.com   \n",
       "\n",
       "                                                category  \\\n",
       "0                                                /Travel   \n",
       "1           /Hobbies & Leisure/Outdoors/Hiking & Camping   \n",
       "2      /Autos & Vehicles/Motor Vehicles (By Type)/Off...   \n",
       "3      /Business & Industrial/Construction & Maintena...   \n",
       "4                        /Home & Garden/Home Furnishings   \n",
       "...                                                  ...   \n",
       "27059                    /Reference/Geographic Reference   \n",
       "27060                          /Sports/Team Sports/Rugby   \n",
       "27061             /People & Society/Seniors & Retirement   \n",
       "27062  /Business & Industrial/Agriculture & Forestry/...   \n",
       "27063  /Reference/General Reference/Dictionaries & En...   \n",
       "\n",
       "                                                   title  \n",
       "0      explore the city with our 2-3 hour tourist sca...  \n",
       "1      a blog about hiking around the midwest and beyond  \n",
       "2      find the right side by side accessories for yo...  \n",
       "3      debrovy's is the ideal tarp manufacturer in th...  \n",
       "4      furniture and accessories for your home and of...  \n",
       "...                                                  ...  \n",
       "27059  an extensive collection of information coverin...  \n",
       "27060  watch every game of major league rugby live an...  \n",
       "27061  the senior list offers the best advice for sen...  \n",
       "27062  backyard chickens from my pet chicken: offerin...  \n",
       "27063  find definitions, language articles, and help ...  \n",
       "\n",
       "[27064 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "website_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b1a3790-0cdb-4565-baf5-32479406a0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\",\n",
    "             \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\",\n",
    "             \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\",\n",
    "             \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\",\n",
    "             \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\",\n",
    "             \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\",\n",
    "             \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\",\n",
    "             \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\",\n",
    "             \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\",\n",
    "             \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\",\n",
    "             \"your\", \"yours\", \"yourself\", \"yourselves\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b75b36cf-f98a-415c-b0c9-204ef86b19b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing functions\n",
    "# remove stopwords from titles\n",
    "def remove_stopwords(data):\n",
    "  data['title'] = data['title'].apply(lambda x : ' '.join([word for word in str(x).split() if word not in (stopwords)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d503336-1cd2-42b1-a1ab-bd87f4496ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take away all punctuation \n",
    "def remove_punctuation(test_str):\n",
    "# Using filter() and lambda function to filter out punctuation characters\n",
    "  result = ''.join(filter(lambda x: x.isalpha() or x.isdigit() or x.isspace(), test_str))\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7f19c83-fd2e-414c-bf70-a4b1af681250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the first general category only\n",
    "def reduce_labels(label):\n",
    "  ans = ''\n",
    "  for char in str(label)[1:]:\n",
    "    if char=='/':\n",
    "      return ans\n",
    "    else:\n",
    "      ans+=char\n",
    "  return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af93b096-e01c-4a92-8290-eb65eec7c6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes all the stopwords from our csv file\n",
    "remove_stopwords(website_categories)\n",
    "# apply the reduce_labels function to each element in the category column\n",
    "website_categories['category'] = website_categories['category'].apply(reduce_labels)\n",
    "# apply the remove_punctuation to each element in the title column\n",
    "website_categories['title'] = website_categories['title'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f58eb15-15b0-4684-8d86-6a578389bac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Travel': 0,\n",
       " 'Hobbies & Leisure': 1,\n",
       " 'Autos & Vehicles': 2,\n",
       " 'Business & Industrial': 3,\n",
       " 'Home & Garden': 4,\n",
       " 'Online Communities': 5,\n",
       " 'Arts & Entertainment': 6,\n",
       " 'Shopping': 7,\n",
       " 'People & Society': 8,\n",
       " 'Reference': 9,\n",
       " 'Beauty & Fitness': 10,\n",
       " 'Law & Government': 11,\n",
       " 'Health': 12,\n",
       " 'Books & Literature': 13,\n",
       " 'News': 14,\n",
       " 'Games': 15,\n",
       " 'Food & Drink': 16,\n",
       " 'Adult': 17,\n",
       " 'Finance': 18,\n",
       " 'Jobs & Education': 19,\n",
       " 'Internet & Telecom': 20,\n",
       " 'Sports': 21,\n",
       " 'Real Estate': 22,\n",
       " 'Computers & Electronics': 23,\n",
       " 'Science': 24,\n",
       " 'Sensitive Subjects': 25,\n",
       " 'Pets & Animals': 26,\n",
       " 'an': 27,\n",
       " 'Business and Consumer Services': 28,\n",
       " 'Computers Electronics and Technology': 29,\n",
       " 'eCommerce & Shopping': 30,\n",
       " 'Science and Education': 31,\n",
       " 'Reference Materials': 32,\n",
       " 'Vehicles': 33,\n",
       " 'Law and Government': 34,\n",
       " 'Food and Drink': 35,\n",
       " 'Travel and Tourism': 36,\n",
       " 'Community and Society': 37,\n",
       " 'Gambling': 38,\n",
       " 'Lifestyle': 39,\n",
       " 'Hobbies and Leisure': 40,\n",
       " 'Home and Garden': 41,\n",
       " 'Heavy Industry and Engineering': 42,\n",
       " 'Jobs and Career': 43,\n",
       " 'Pets and Animals': 44}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a list of unique categories\n",
    "categories = website_categories['category'].unique()\n",
    "# enumerate the categories by index and map the category to its index in the dictionary\n",
    "class_names = {}\n",
    "for i,category in enumerate(categories):\n",
    "  class_names[category] = i\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "813ba3cf-1b34-4054-9042-e8063e81b430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "Business & Industrial                   3005\n",
       "Arts & Entertainment                    2412\n",
       "Shopping                                2338\n",
       "Internet & Telecom                      2049\n",
       "Hobbies & Leisure                       1683\n",
       "Computers & Electronics                 1429\n",
       "People & Society                        1323\n",
       "Home & Garden                           1276\n",
       "Health                                  1014\n",
       "Online Communities                       920\n",
       "Sports                                   893\n",
       "Jobs & Education                         890\n",
       "Autos & Vehicles                         866\n",
       "Food & Drink                             781\n",
       "News                                     773\n",
       "Beauty & Fitness                         647\n",
       "Games                                    640\n",
       "Travel                                   630\n",
       "Adult                                    529\n",
       "Law & Government                         513\n",
       "Books & Literature                       510\n",
       "Finance                                  443\n",
       "Reference                                412\n",
       "Science                                  341\n",
       "Sensitive Subjects                       305\n",
       "Real Estate                              236\n",
       "Pets & Animals                            47\n",
       "Computers Electronics and Technology      29\n",
       "Science and Education                     15\n",
       "Lifestyle                                 13\n",
       "Gambling                                  11\n",
       "Heavy Industry and Engineering            10\n",
       "Home and Garden                           10\n",
       "Hobbies and Leisure                       10\n",
       "Community and Society                      9\n",
       "Travel and Tourism                         7\n",
       "Food and Drink                             7\n",
       "an                                         7\n",
       "Vehicles                                   7\n",
       "Law and Government                         6\n",
       "eCommerce & Shopping                       6\n",
       "Business and Consumer Services             6\n",
       "Reference Materials                        3\n",
       "Jobs and Career                            2\n",
       "Pets and Animals                           1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def apply_encodings(category):\n",
    "  return class_names[category]\n",
    "# count the occurrences of each unique value in the category column in descending order\n",
    "website_categories['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9362d2a7-1928-4e15-a06f-2127d69330be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Travel',\n",
       " 1: 'Hobbies & Leisure',\n",
       " 2: 'Autos & Vehicles',\n",
       " 3: 'Business & Industrial',\n",
       " 4: 'Home & Garden',\n",
       " 5: 'Online Communities',\n",
       " 6: 'Arts & Entertainment',\n",
       " 7: 'Shopping',\n",
       " 8: 'People & Society',\n",
       " 9: 'Reference',\n",
       " 10: 'Beauty & Fitness',\n",
       " 11: 'Law & Government',\n",
       " 12: 'Health',\n",
       " 13: 'Books & Literature',\n",
       " 14: 'News',\n",
       " 15: 'Games',\n",
       " 16: 'Food & Drink',\n",
       " 17: 'Adult',\n",
       " 18: 'Finance',\n",
       " 19: 'Jobs & Education',\n",
       " 20: 'Internet & Telecom',\n",
       " 21: 'Sports',\n",
       " 22: 'Real Estate',\n",
       " 23: 'Computers & Electronics',\n",
       " 24: 'Science',\n",
       " 25: 'Sensitive Subjects',\n",
       " 26: 'Pets & Animals',\n",
       " 27: 'an',\n",
       " 28: 'Business and Consumer Services',\n",
       " 29: 'Computers Electronics and Technology',\n",
       " 30: 'eCommerce & Shopping',\n",
       " 31: 'Science and Education',\n",
       " 32: 'Reference Materials',\n",
       " 33: 'Vehicles',\n",
       " 34: 'Law and Government',\n",
       " 35: 'Food and Drink',\n",
       " 36: 'Travel and Tourism',\n",
       " 37: 'Community and Society',\n",
       " 38: 'Gambling',\n",
       " 39: 'Lifestyle',\n",
       " 40: 'Hobbies and Leisure',\n",
       " 41: 'Home and Garden',\n",
       " 42: 'Heavy Industry and Engineering',\n",
       " 43: 'Jobs and Career',\n",
       " 44: 'Pets and Animals'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inverse map from encodings to classnames\n",
    "inv_map = {v: k for k, v in class_names.items()}\n",
    "inv_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b620dd67-a719-4578-8349-d3ce701b2cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Internet &amp; Telecom/Web Services/Web Design &amp; ...</td>\n",
       "      <td>1043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Business &amp; Industrial</td>\n",
       "      <td>992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/People &amp; Society/Religion &amp; Belief</td>\n",
       "      <td>666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Internet &amp; Telecom</td>\n",
       "      <td>590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/News</td>\n",
       "      <td>575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>/Science/Physics</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>/Sports/Boxing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>/Finance/Investing/Stocks &amp; Bonds</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>/Food &amp; Drink/Restaurants/Restaurant Reviews &amp;...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>/Reference/Geographic Reference</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>560 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Unnamed: 0  category\n",
       "0    /Internet & Telecom/Web Services/Web Design & ...      1043\n",
       "1                               /Business & Industrial       992\n",
       "2                  /People & Society/Religion & Belief       666\n",
       "3                                  /Internet & Telecom       590\n",
       "4                                                /News       575\n",
       "..                                                 ...       ...\n",
       "555                                   /Science/Physics         1\n",
       "556                                     /Sports/Boxing         1\n",
       "557                  /Finance/Investing/Stocks & Bonds         1\n",
       "558  /Food & Drink/Restaurants/Restaurant Reviews &...         1\n",
       "559                    /Reference/Geographic Reference         1\n",
       "\n",
       "[560 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_counts = pd.read_csv('value_counts.csv')\n",
    "value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af85184b-e4db-4ab4-8c76-617d84dc9ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_9_categories = ['Business & Industrial','Arts & Entertainment','Shopping','Internet & Telecom','Hobbies & Leisure','Computers & Electronics','People & Society','Home & Garden','Health']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b79fe0a-2c2e-4219-895b-2cf990a00051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only include rows where the category column's value is in a specified list of top categories.\n",
    "top_9 = website_categories.loc[website_categories['category'].isin(top_9_categories)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2d0e391-da88-4782-93de-2ee57b18856e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only the category and title columns\n",
    "top_9 = top_9[['category','title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3da8262e-5eaa-4fe7-84be-10b1d5abe49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 1013\n",
    "# a dictionary to keep track of the number of titles added for each category.\n",
    "top_9_counts = {}\n",
    "category = []\n",
    "title = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "910f322a-0bda-47e3-ac60-c8ab6de9e3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in top_9.iterrows():\n",
    "  # if the category is not in the dictionary, initialize it with a count of 0 and add the title and category to the lists\n",
    "  if row['category'] not in top_9_counts.keys():\n",
    "    top_9_counts[row['category']] = 0\n",
    "    title.append(row['title'])\n",
    "    category.append(row['category'])\n",
    "\n",
    "  elif top_9_counts[row['category']]<max_length:\n",
    "    top_9_counts[row['category']]+=1\n",
    "    title.append(row['title'])\n",
    "    category.append(row['category'])\n",
    "\n",
    "final_top_9 = pd.DataFrame()\n",
    "final_top_9['category'] = category\n",
    "final_top_9['title'] = title\n",
    "\n",
    "# apply the encodings the final list\n",
    "encoded_categories = final_top_9['category'].apply(apply_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49450891-a1d9-420e-bb67-6a73f4013c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test,Y_train, Y_test = sklearn.model_selection.train_test_split(final_top_9['title'], encoded_categories, test_size=0.2, random_state = 45)\n",
    "# initializes a tokenizer that will consider the top 50,000 most frequent words from text data\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words = 50000)\n",
    "# fits the tokenizer on the training text data, and builds the vocabulary based on the training data\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "# generates a dictionary (word_index) where each word in the vocabulary is mapped to an integer index\n",
    "words_to_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "976940e2-597c-4eba-bebb-e3143a73300a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-08-08 18:21:21--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182613 (822M) [application/zip]\n",
      "Saving to: ‘glove.6B.zip’\n",
      "\n",
      "glove.6B.zip        100%[===================>] 822.24M   518KB/s    in 14m 47s \n",
      "\n",
      "2024-08-08 18:36:08 (950 KB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
    "!unzip -q glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "30039cc2-2b16-4066-b879-4eb0edda8a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# use Glove Embeddings\n",
    "path_to_glove_file = 'glove.6B.50d.txt'\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(path_to_glove_file) as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e2f9f864-651a-4d61-a277-cbac0c32ea5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TextVectorization(max_tokens=20000, output_sequence_length=25)\n",
    "vectorizer.adapt(final_top_9['title'])\n",
    "x_train = vectorizer(np.array([[s] for s in X_train])).numpy()\n",
    "x_val = vectorizer(np.array([[s] for s in X_test])).numpy()\n",
    "y_train = np.array(Y_train)\n",
    "y_val = np.array(Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7491ab82-d201-46a7-9a15-fd0e31919ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 16423 words (7111 misses)\n"
     ]
    }
   ],
   "source": [
    "num_tokens = len(words_to_index) + 2\n",
    "embedding_dim = 50\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in words_to_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ca174b7-fd65-4937-9595-a82a098a5e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = tf.keras.layers.Embedding(\n",
    "    num_tokens,\n",
    "    embedding_dim,\n",
    "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "    trainable=False,\n",
    ")\n",
    "\n",
    "int_sequences_input = keras.Input(shape=(None,), dtype=\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e3d7758-6dd0-4cc7-b204-c92f29e8fdbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, None, 50)          1176800   \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, None, 128)         32128     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, 128)         0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, None, 128)         82048     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, None, 128)         0         \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 128)              0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               12900     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 45)                4545      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,308,421\n",
      "Trainable params: 131,621\n",
      "Non-trainable params: 1,176,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedded_sequences = embedding_layer(int_sequences_input)\n",
    "x = tf.keras.layers.Conv1D(128, 5, activation=\"relu\")(embedded_sequences)\n",
    "x = tf.keras.layers.Dropout(0.25)(x)\n",
    "x = tf.keras.layers.Conv1D(128, 5, activation=\"relu\")(x)\n",
    "x = tf.keras.layers.Dropout(.2)(x)\n",
    "x = tf.keras.layers.GlobalMaxPooling1D()(x)\n",
    "x = tf.keras.layers.Dense(100, activation=\"relu\")(x)\n",
    "\n",
    "preds = tf.keras.layers.Dense(len(class_names), activation=\"softmax\")(x)\n",
    "model = tf.keras.Model(int_sequences_input, preds)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f0df70f2-a243-4d0e-8287-dfbfea4c2485",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(0.001), metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "adec5463-6bc2-408d-aadb-883859806e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "58/58 [==============================] - 2s 40ms/step - loss: 0.2779 - accuracy: 0.9053 - val_loss: 3.1221 - val_accuracy: 0.3549\n",
      "Epoch 2/40\n",
      "58/58 [==============================] - 2s 35ms/step - loss: 0.3077 - accuracy: 0.8977 - val_loss: 3.0566 - val_accuracy: 0.3505\n",
      "Epoch 3/40\n",
      "58/58 [==============================] - 2s 38ms/step - loss: 0.2832 - accuracy: 0.9062 - val_loss: 3.1113 - val_accuracy: 0.3456\n",
      "Epoch 4/40\n",
      "58/58 [==============================] - 2s 35ms/step - loss: 0.2803 - accuracy: 0.9060 - val_loss: 3.1993 - val_accuracy: 0.3330\n",
      "Epoch 5/40\n",
      "58/58 [==============================] - 2s 37ms/step - loss: 0.3284 - accuracy: 0.8890 - val_loss: 3.1045 - val_accuracy: 0.3467\n",
      "Epoch 6/40\n",
      "58/58 [==============================] - 2s 36ms/step - loss: 0.3757 - accuracy: 0.8767 - val_loss: 3.1312 - val_accuracy: 0.3483\n",
      "Epoch 7/40\n",
      "58/58 [==============================] - 2s 37ms/step - loss: 0.3005 - accuracy: 0.8971 - val_loss: 3.0736 - val_accuracy: 0.3510\n",
      "Epoch 8/40\n",
      "58/58 [==============================] - 2s 39ms/step - loss: 0.2836 - accuracy: 0.9041 - val_loss: 3.0624 - val_accuracy: 0.3406\n",
      "Epoch 9/40\n",
      "58/58 [==============================] - 2s 36ms/step - loss: 0.2796 - accuracy: 0.9073 - val_loss: 3.0729 - val_accuracy: 0.3521\n",
      "Epoch 10/40\n",
      "58/58 [==============================] - 2s 39ms/step - loss: 0.2709 - accuracy: 0.9089 - val_loss: 3.1063 - val_accuracy: 0.3521\n",
      "Epoch 11/40\n",
      "58/58 [==============================] - 2s 37ms/step - loss: 0.2701 - accuracy: 0.9090 - val_loss: 3.1741 - val_accuracy: 0.3494\n",
      "Epoch 12/40\n",
      "58/58 [==============================] - 3s 44ms/step - loss: 0.2736 - accuracy: 0.9079 - val_loss: 3.1283 - val_accuracy: 0.3461\n",
      "Epoch 13/40\n",
      "58/58 [==============================] - 2s 38ms/step - loss: 0.2761 - accuracy: 0.9063 - val_loss: 3.0942 - val_accuracy: 0.3390\n",
      "Epoch 14/40\n",
      "58/58 [==============================] - 2s 41ms/step - loss: 0.3534 - accuracy: 0.8896 - val_loss: 3.0394 - val_accuracy: 0.3472\n",
      "Epoch 15/40\n",
      "58/58 [==============================] - 2s 38ms/step - loss: 0.2910 - accuracy: 0.9016 - val_loss: 3.0799 - val_accuracy: 0.3330\n",
      "Epoch 16/40\n",
      "58/58 [==============================] - 2s 39ms/step - loss: 0.2899 - accuracy: 0.8975 - val_loss: 3.0582 - val_accuracy: 0.3406\n",
      "Epoch 17/40\n",
      "58/58 [==============================] - 2s 39ms/step - loss: 0.2845 - accuracy: 0.9038 - val_loss: 3.1015 - val_accuracy: 0.3373\n",
      "Epoch 18/40\n",
      "58/58 [==============================] - 2s 41ms/step - loss: 0.3027 - accuracy: 0.8986 - val_loss: 3.0652 - val_accuracy: 0.3472\n",
      "Epoch 19/40\n",
      "58/58 [==============================] - 2s 41ms/step - loss: 0.2749 - accuracy: 0.9088 - val_loss: 3.1010 - val_accuracy: 0.3483\n",
      "Epoch 20/40\n",
      "58/58 [==============================] - 2s 39ms/step - loss: 0.2759 - accuracy: 0.9064 - val_loss: 3.0709 - val_accuracy: 0.3494\n",
      "Epoch 21/40\n",
      "58/58 [==============================] - 2s 41ms/step - loss: 0.2476 - accuracy: 0.9173 - val_loss: 3.0583 - val_accuracy: 0.3521\n",
      "Epoch 22/40\n",
      "58/58 [==============================] - 3s 48ms/step - loss: 0.2667 - accuracy: 0.9085 - val_loss: 3.2039 - val_accuracy: 0.3445\n",
      "Epoch 23/40\n",
      "58/58 [==============================] - 2s 43ms/step - loss: 0.3123 - accuracy: 0.8938 - val_loss: 3.0767 - val_accuracy: 0.3494\n",
      "Epoch 24/40\n",
      "58/58 [==============================] - 2s 42ms/step - loss: 0.2760 - accuracy: 0.9055 - val_loss: 3.1307 - val_accuracy: 0.3401\n",
      "Epoch 25/40\n",
      "58/58 [==============================] - 3s 46ms/step - loss: 0.3198 - accuracy: 0.8971 - val_loss: 2.9970 - val_accuracy: 0.3521\n",
      "Epoch 26/40\n",
      "58/58 [==============================] - 3s 53ms/step - loss: 0.2734 - accuracy: 0.9088 - val_loss: 3.1693 - val_accuracy: 0.3341\n",
      "Epoch 27/40\n",
      "58/58 [==============================] - 3s 50ms/step - loss: 0.3420 - accuracy: 0.8911 - val_loss: 3.0348 - val_accuracy: 0.3510\n",
      "Epoch 28/40\n",
      "58/58 [==============================] - 2s 42ms/step - loss: 0.2826 - accuracy: 0.9074 - val_loss: 3.0718 - val_accuracy: 0.3461\n",
      "Epoch 29/40\n",
      "58/58 [==============================] - 3s 45ms/step - loss: 0.2682 - accuracy: 0.9096 - val_loss: 3.0508 - val_accuracy: 0.3483\n",
      "Epoch 30/40\n",
      "58/58 [==============================] - 3s 48ms/step - loss: 0.2724 - accuracy: 0.9082 - val_loss: 3.0775 - val_accuracy: 0.3560\n",
      "Epoch 31/40\n",
      "58/58 [==============================] - 3s 47ms/step - loss: 0.2572 - accuracy: 0.9133 - val_loss: 3.0989 - val_accuracy: 0.3505\n",
      "Epoch 32/40\n",
      "58/58 [==============================] - 3s 45ms/step - loss: 0.2516 - accuracy: 0.9162 - val_loss: 3.0572 - val_accuracy: 0.3642\n",
      "Epoch 33/40\n",
      "58/58 [==============================] - 3s 53ms/step - loss: 0.2336 - accuracy: 0.9207 - val_loss: 3.0916 - val_accuracy: 0.3527\n",
      "Epoch 34/40\n",
      "58/58 [==============================] - 3s 58ms/step - loss: 0.2433 - accuracy: 0.9185 - val_loss: 3.1340 - val_accuracy: 0.3499\n",
      "Epoch 35/40\n",
      "58/58 [==============================] - 3s 56ms/step - loss: 0.2622 - accuracy: 0.9114 - val_loss: 3.1710 - val_accuracy: 0.3373\n",
      "Epoch 36/40\n",
      "58/58 [==============================] - 3s 49ms/step - loss: 0.2803 - accuracy: 0.9089 - val_loss: 3.0670 - val_accuracy: 0.3560\n",
      "Epoch 37/40\n",
      "58/58 [==============================] - 2s 41ms/step - loss: 0.2509 - accuracy: 0.9123 - val_loss: 3.2061 - val_accuracy: 0.3467\n",
      "Epoch 38/40\n",
      "58/58 [==============================] - 3s 46ms/step - loss: 0.2425 - accuracy: 0.9159 - val_loss: 3.1339 - val_accuracy: 0.3620\n",
      "Epoch 39/40\n",
      "58/58 [==============================] - 3s 58ms/step - loss: 0.2419 - accuracy: 0.9181 - val_loss: 3.1386 - val_accuracy: 0.3636\n",
      "Epoch 40/40\n",
      "58/58 [==============================] - 3s 45ms/step - loss: 0.2308 - accuracy: 0.9204 - val_loss: 3.1675 - val_accuracy: 0.3538\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x171e218e0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=128, epochs=40, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "151ba1ab-48e9-4fe2-9848-61e53273bfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_using_model(model, phrase, inv_map):\n",
    "  string_input = keras.Input(shape=(1,), dtype=\"string\")\n",
    "  x = vectorizer(string_input)\n",
    "  preds = model(x)\n",
    "  end_to_end_model = keras.Model(string_input, preds)\n",
    "\n",
    "  probabilities = end_to_end_model.predict(\n",
    "    [[phrase]]\n",
    "  )\n",
    "  high = np.argmax(probabilities)\n",
    "  return inv_map[high]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0c5625a2-7909-4c49-9b12-b885f8ca93c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 274ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'People & Society'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_using_model(model, 'friends', inv_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3ebabd37-e48c-495a-b472-0dd3afcc9957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def returntitle(url):\n",
    "  try:\n",
    "    request = requests.get(url)\n",
    "  except:\n",
    "    return 'error'\n",
    "  Soup = BeautifulSoup(request.text, 'html.parser')\n",
    "  title_tag = Soup.find('title')\n",
    "  if title_tag:\n",
    "    title_text = title_tag.text\n",
    "  return title_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2287df53-42aa-441c-b1ba-b109662c8a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize(url):\n",
    "  title = returntitle(url)\n",
    "  category = predict_using_model(model, title, inv_map)\n",
    "  return category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8aeb5aa4-44d4-4efa-b9e7-168bfa7eb57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 153ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'People & Society'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorize('https://myanimelist.net/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ed5f8e28-81f5-4ec7-8c0d-83835aff9e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 184ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Internet & Telecom'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorize('https://github.com/tnhi26990?tab=repositories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "79b667b1-e9e7-4876-807f-22b0f9afee2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 272ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Home & Garden'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorize('https://www.youtube.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b6e5f123-458a-49e7-990e-a41e6c85f6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x172556ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 164ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Arts & Entertainment'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorize('https://www.netflix.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757b8ddd-89f7-4526-aed1-bff1e2c74f9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
